#+PROPERTY: header-args:python :session :results output :exports both
* Outline
- This is an attempt to integrate both proiel_trf & grc_ner into a model, outputting in a .conllu format

** Code - script for _trf, _ner 

*** run_proiel_trf.py
#+begin_src python :results output :eval never
  import spacy
  import json
  import os

  nlp = spacy.load("proiel_trf")

  input_folder = "/path/to/corpus/"
  output_folder = "/path/to/results/"

  os.makedirs(output_folder, exist_ok=True)

  for filename in os.listdir(input_folder):
      if filename.endswith(".txt"):
          file_path = os.path.join(input_folder, filename)
          with open(file_path, "r", encoding="utf-8") as f:
              text = f.read()

          doc = nlp(text)

          # Save dependency parsing results
          output_path = os.path.join(output_folder, filename.replace(".txt", "_trf.json"))
          with open(output_path, "w", encoding="utf-8") as f:
              json.dump(doc.to_json(), f, ensure_ascii=False, indent=4)

  print("proiel_trf processing completed.")

#+end_src

*** run_NER.py

#+begin_src python :results output :eval never
  import spacy
  import json
  import os

  nlp = spacy.load("proiel_ner")

  input_folder = "/path/to/corpus/"
  output_folder = "/path/to/results/"

  for filename in os.listdir(input_folder):
      if filename.endswith(".txt"):
          file_path = os.path.join(input_folder, filename)
          with open(file_path, "r", encoding="utf-8") as f:
              text = f.read()

          doc = nlp(text)

          # Save NER results
          output_path = os.path.join(output_folder, filename.replace(".txt", "_ner.json"))
          with open(output_path, "w", encoding="utf-8") as f:
              json.dump(doc.to_json(), f, ensure_ascii=False, indent=4)

  print("proiel_ner processing completed.")
#+end_src
** Code - using babel to switch environments
*** Running proiel_trf - full text
#+BEGIN_SRC python :session proiel_trf :results output
import os
os.system("conda run -n proiel_trf python ~/Documents/au_work/main/comp_antiquity/combined_approach/run_proiel_trf.py")
#+END_SRC



*** Running proiel_ner - full text

#+BEGIN_SRC python :session ner :results output :eval never
import os
os.system("conda run -n ner python ~/Documents/au_work/main/comp_antiquity/combined_approach/run_ner.py")
#+END_SRC

#+RESULTS:
: ‚úÖ NER processing completed.
: 
: /home/gnosis/.conda/envs/ner/lib/python3.9/site-packages/thinc/shims/pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
:   with torch.cuda.amp.autocast(self._mixed_precision):

** Merging results in a UD-compliant .conllu-file

*** merge_results.py
**** .json vil ikke merges til en .conllu her :)
#+begin_src python :results output :eval never
  import json
  import os
  import pandas as pd

  input_folder = "~/Documents/au_work/main/corpora/trf_ner_v2_results/"
  output_folder = "~/Documents/au_work/main/corpora/trf_ner_v2_results_conllu/"

  os.makedirs(output_folder, exist_ok=True)

# Collect all .jsonl files
json_files = [f for f in os.listdir(input_folder) if f.endswith(".json")]

# Find matching _trf.json and _ner.json files
file_pairs = {}
for filename in json_files:
    base_name = filename.replace("_trf.json", "").replace("_ner.json", "")

    if base_name not in file_pairs:
        file_pairs[base_name] = {}

    if filename.endswith("_trf.json"):
        file_pairs[base_name]["trf"] = os.path.join(input_folder, filename)
    elif filename.endswith("_ner.json"):
        file_pairs[base_name]["ner"] = os.path.join(input_folder, filename)

# Merge TRF and NER files into CoNLL-U format
for base_name, paths in file_pairs.items():
    if "trf" not in paths or "ner" not in paths:
        print(f"‚ö†Ô∏è Warning: Missing TRF or NER file for {base_name}, skipping merge.")
        continue

    trf_path = paths["trf"]
    ner_path = paths["ner"]
    conllu_filename = os.path.join(output_folder, base_name + ".conllu")

    with open(trf_path, "r", encoding="utf-8") as trf_file, \
         open(ner_path, "r", encoding="utf-8") as ner_file, \
         open(conllu_filename, "w", encoding="utf-8") as conllu_file:

        conllu_file.write("# This file follows Universal Dependencies format\n\n")

        # Load JSON lines into dictionaries indexed by "id"
        trf_data = {entry["id"]: entry for entry in map(json.loads, trf_file)}
        ner_data = {entry["id"]: entry for entry in map(json.loads, ner_file)}

        # Merge TRF and NER entries based on "id"
        for token_id in sorted(trf_data.keys()):  # Ensure correct order
            trf_entry = trf_data[token_id]
            ner_entry = ner_data.get(token_id, {"ner": "O"})  # Default to "O" if missing

            # ‚úÖ Extract token attributes safely
            form = trf_entry.get("text", "_")
            lemma = trf_entry.get("lemma", "_")
            upos = trf_entry.get("upos", "_")
            xpos = trf_entry.get("xpos", "_")
            feats = trf_entry.get("feats", "_")
            head = trf_entry.get("head", 0)
            deprel = trf_entry.get("dep", "_")
            deps = trf_entry.get("deps", "_")
            ner_label = ner_entry.get("ner", "O")

            # üìå Store Named Entity Label in MISC
            misc_field = f"NER={ner_label}" if ner_label != "O" else "_"

            # üìå Append token data to CoNLL-U format
            conllu_row = [token_id, form, lemma, upos, xpos, feats, head, deprel, deps, misc_field]
            conllu_file.write("\t".join(map(str, conllu_row)) + "\n")

        conllu_file.write("\n")  # Separate sentences with a blank line

print("‚úÖ Merged proiel_trf and NER outputs into CoNLL-U format.")
#+end_src

#+RESULTS:
**** nyt fors√∏g

#+begin_src python :results output
  import os
  import json
  import re  # ‚úÖ Regex for flexible filename matching

  input_folder = "/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results"
  # debug - check files are actually located in input
  # files = os.listdir(input_folder)
  # print("üìÇ Files in input folder:", files)
  output_folder = "/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results_conllu"

  os.makedirs(output_folder, exist_ok=True)

  # Collect all .json files (assuming they are NDJSON)
  json_files = [f for f in os.listdir(input_folder) if f.endswith(".json")]

  # Find matching _trf.json and _ner.json files
  file_pairs = {}
  for filename in json_files:
      # Remove `_trf.json` or `_ner.json` to get the base name
      base_name = re.sub(r"(_trf|_ner)\.json$", "", filename)
      print(f"Processing file: {filename} ‚Üí Base name detected: {base_name}")

      if base_name not in file_pairs:
          file_pairs[base_name] = {}

      if filename.endswith("_trf.json"):
          file_pairs[base_name]["trf"] = os.path.join(input_folder, filename)
      elif filename.endswith("_ner.json"):
          file_pairs[base_name]["ner"] = os.path.join(input_folder, filename)

  # Debugging: Print detected file pairs
  print(f"üîç Detected file pairs: {file_pairs}")

  # Merge TRF and NER files into CoNLL-U format
  for base_name, paths in file_pairs.items():
      if "trf" not in paths or "ner" not in paths:
          print(f"‚ö†Ô∏è Warning: Missing TRF or NER file for {base_name}, skipping merge.")
          continue

      trf_path = paths["trf"]
      ner_path = paths["ner"]
      conllu_filename = os.path.join(output_folder, base_name + ".conllu")

      with open(trf_path, "r", encoding="utf-8") as trf_file, \
           open(ner_path, "r", encoding="utf-8") as ner_file, \
           open(conllu_filename, "w", encoding="utf-8") as conllu_file:

          conllu_file.write("# This file follows Universal Dependencies format\n\n")

          # Read NDJSON line-by-line
          trf_data = {entry["id"]: entry for entry in map(json.loads, trf_file)}
          ner_data = {entry["id"]: entry for entry in map(json.loads, ner_file)}

          # Debugging: Check if data is being read
          print(f"üìÑ Processing {base_name}: {len(trf_data)} tokens found in TRF")
          print(f"üìÑ Processing {base_name}: {len(ner_data)} tokens found in NER")

          # Merge TRF and NER based on "id"
          for token_id in sorted(trf_data.keys()):  # Ensure correct order
              trf_entry = trf_data[token_id]
              ner_entry = ner_data.get(token_id, {"ner": "O"})  # Default to "O"

              # ‚úÖ Extract token attributes
              form = trf_entry.get("text", "_")
              lemma = trf_entry.get("lemma", "_")
              upos = trf_entry.get("upos", "_")
              xpos = "_"
              feats = trf_entry.get("feats", "_")
              head = trf_entry.get("head", 0)
              deprel = trf_entry.get("dep", "_")
              deps = trf_entry.get("deps", "_")
              ner_label = ner_entry.get("ner", "O")

              # üè∑Ô∏è Store Named Entity Label in MISC
              misc_field = f"NER={ner_label}" if ner_label != "O" else "_"

              # üìå Append token data to CoNLL-U format
              conllu_row = [token_id, form, lemma, upos, xpos, feats, head, deprel, deps, misc_field]
              conllu_file.write("\t".join(map(str, conllu_row)) + "\n")

          conllu_file.write("\n")  # Separate sentences with a blank line

  print("‚úÖ Merged proiel_trf and NER outputs into CoNLL-U format.")
#+end_src

#+RESULTS:
: üîç Detected file pairs: {'NA28-050PHP': {'trf': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/NA28-050PHP_trf.json', 'ner': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/NA28-050PHP_ner.json'}, 'NA28-041MRK': {'trf': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/NA28-041MRK_trf.json', 'ner': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/NA28-041MRK_ner.json'}, 'NA28-044ACT': {'trf': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/NA28-044ACT_trf.json', 'ner': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/NA28-044ACT_ner.json'}, 'NA28-0601PE': {'trf': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/NA28-0601PE_trf.json', 'ner': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/NA28-0601PE_ner.json'}, 'SEP-001GEN': {'trf': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/SEP-001GEN_trf.json', 'ner': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/SEP-001GEN_ner.json'}, 'SEP-007JDG': {'trf': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/SEP-007JDG_trf.json', 'ner': '/home/gnosis/Documents/au_work/main/corpora/trf_ner_v2_results/SEP-007JDG_ner.json'}}
: üìÑ Processing NA28-050PHP: 1882 tokens found in TRF
: üìÑ Processing NA28-041MRK: 2275 tokens found in TRF
: üìÑ Processing NA28-044ACT: 2229 tokens found in TRF
: üìÑ Processing NA28-0601PE: 1894 tokens found in TRF
: üìÑ Processing SEP-001GEN: 2227 tokens found in TRF
: üìÑ Processing SEP-007JDG: 2192 tokens found in TRF
: ‚úÖ Merged proiel_trf and NER outputs into CoNLL-U format.
